{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=None\n",
    "all_variables=None\n",
    "test_path=None\n",
    "# target='search_term'\n",
    "target='Dataset'\n",
    "nthreads=1 \n",
    "min_mem_size=6 \n",
    "run_time=200\n",
    "classification=False\n",
    "scale=False\n",
    "max_models=9    \n",
    "model_path=None\n",
    "balance_y=False \n",
    "balance_threshold=0.2\n",
    "name=None \n",
    "server_path=None  \n",
    "analysis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pct_memory=0.5\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(min_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabet(n):\n",
    "  alpha='0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'    \n",
    "  str=''\n",
    "  r=len(alpha)-1   \n",
    "  while len(str)<n:\n",
    "    i=random.randint(0,r)\n",
    "    str+=alpha[i]   \n",
    "  return str\n",
    "  \n",
    "  \n",
    "def set_meta_data(analysis,run_id,server,data,test,model_path,target,run_time,classification,scale,model,balance,balance_threshold,name,path,nthreads,min_mem_size):\n",
    "  m_data={}\n",
    "  m_data['start_time'] = time.time()\n",
    "  m_data['target']=target\n",
    "  m_data['server_path']=server\n",
    "  m_data['data_path']=data \n",
    "  m_data['test_path']=test\n",
    "  m_data['max_models']=model\n",
    "  m_data['run_time']=run_time\n",
    "  m_data['run_id'] =run_id\n",
    "  m_data['scale']=scale\n",
    "  m_data['classification']=classification\n",
    "  m_data['scale']=False\n",
    "  m_data['model_path']=model_path\n",
    "  m_data['balance']=balance\n",
    "  m_data['balance_threshold']=balance_threshold\n",
    "  m_data['project'] =name\n",
    "  m_data['end_time'] = time.time()\n",
    "  m_data['execution_time'] = 0.0\n",
    "  m_data['run_path'] =path\n",
    "  m_data['nthreads'] = nthreads\n",
    "  m_data['min_mem_size'] = min_mem_size\n",
    "  m_data['analysis'] = analysis\n",
    "  return m_data\n",
    "\n",
    "\n",
    "def dict_to_json(dct,n):\n",
    "  j = json.dumps(dct, indent=4)\n",
    "  f = open(n, 'w')\n",
    "  print(j, file=f)\n",
    "  f.close()\n",
    "    \n",
    "#all_variables=None\n",
    "def stackedensemble(mod):\n",
    "    coef_norm = None\n",
    "    try:\n",
    "      metalearner = h2o.get_model(mod.metalearner()['name'])\n",
    "      coef_norm = metalearner.coef_norm()\n",
    "    except:\n",
    "      pass        \n",
    "    return coef_norm\n",
    "\n",
    "def stackedensemble_df(df):\n",
    "    bm_algo={ 'GBM': None,'GLM': None,'DRF': None,'XRT': None,'Dee': None}\n",
    "    for index, row in df.iterrows():\n",
    "      if len(row['model_id'])>3:\n",
    "        key=row['model_id'][0:3]\n",
    "        if key in bm_algo:\n",
    "          if bm_algo[key] is None:\n",
    "                bm_algo[key]=row['model_id']\n",
    "    bm=list(bm_algo.values()) \n",
    "    bm=list(filter(None.__ne__, bm))             \n",
    "    return bm\n",
    "\n",
    "def se_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['auc']=modl.auc()   \n",
    "    d['roc']=modl.roc()\n",
    "    d['mse']=modl.mse()   \n",
    "    d['null_degrees_of_freedom']=modl.null_degrees_of_freedom()\n",
    "    d['null_deviance']=modl.null_deviance()\n",
    "    d['residual_degrees_of_freedom']=modl.residual_degrees_of_freedom()   \n",
    "    d['residual_deviance']=modl.residual_deviance()\n",
    "    d['rmse']=modl.rmse()\n",
    "    return d\n",
    "\n",
    "def get_model_by_algo(algo,models_dict):\n",
    "    mod=None\n",
    "    mod_id=None    \n",
    "    for m in list(models_dict.keys()):\n",
    "        if m[0:3]==algo:\n",
    "            mod_id=m\n",
    "            mod=h2o.get_model(m)      \n",
    "    return mod,mod_id     \n",
    "    \n",
    "    \n",
    "def gbm_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def dl_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def drf_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    d['roc']=modl.roc()      \n",
    "    return d\n",
    "    \n",
    "def xrt_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    d['roc']=modl.roc()      \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def glm_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['coef']=modl.coef()  \n",
    "    d['coef_norm']=modl.coef_norm()      \n",
    "    return d\n",
    "    \n",
    "def model_performance_stats(perf):\n",
    "    d={}\n",
    "    try:    \n",
    "      d['mse']=perf.mse()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['rmse']=perf.rmse() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_degrees_of_freedom']=perf.null_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_degrees_of_freedom']=perf.residual_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_deviance']=perf.residual_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_deviance']=perf.null_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['aic']=perf.aic() \n",
    "    except:\n",
    "      pass      \n",
    "    try:\n",
    "      d['logloss']=perf.logloss() \n",
    "    except:\n",
    "      pass    \n",
    "    try:\n",
    "      d['auc']=perf.auc()\n",
    "    except:\n",
    "      pass  \n",
    "    try:\n",
    "      d['gini']=perf.gini()\n",
    "    except:\n",
    "      pass    \n",
    "    return d\n",
    "    \n",
    "def impute_missing_values(df, x, scal=False):\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in df.types.items():\n",
    "        if key in x:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    _ = df[reals].impute(method='mean')\n",
    "    _ = df[ints].impute(method='median')\n",
    "    if scal:\n",
    "        df[reals] = df[reals].scale()\n",
    "        df[ints] = df[ints].scale()    \n",
    "    return\n",
    "\n",
    "\n",
    "def get_independent_variables(df, targ):\n",
    "    C = [name for name in df.columns if name != targ]\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in df.types.items():\n",
    "        if key in C:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    x=ints+enums+reals\n",
    "    return x\n",
    "    \n",
    "def get_all_variables_csv(i):\n",
    "    ivd={}\n",
    "    try:\n",
    "      iv = pd.read_csv(i,header=None)\n",
    "    except:\n",
    "      sys.exit(1)    \n",
    "    col=iv.values.tolist()[0]\n",
    "    dt=iv.values.tolist()[1]\n",
    "    i=0\n",
    "    for c in col:\n",
    "      ivd[c.strip()]=dt[i].strip()\n",
    "      i+=1        \n",
    "    return ivd\n",
    "    \n",
    "    \n",
    "\n",
    "def check_all_variables(df,dct,y=None):     \n",
    "    targ=list(dct.keys())     \n",
    "    for key, val in df.types.items():\n",
    "        if key in targ:\n",
    "          if dct[key] not in ['real','int','enum']:                      \n",
    "            targ.remove(key)  \n",
    "    for key, val in df.types.items():\n",
    "        if key in targ:            \n",
    "          if dct[key] != val:\n",
    "            print('convert ',key,' ',dct[key],' ',val)\n",
    "            if dct[key]=='enum':\n",
    "                try:\n",
    "                  df[key] = df[key].asfactor() \n",
    "                except:\n",
    "                  targ.remove(key)                 \n",
    "            if dct[key]=='int': \n",
    "                try:                \n",
    "                  df[key] = df[key].asnumeric() \n",
    "                except:\n",
    "                  targ.remove(key)                  \n",
    "            if dct[key]=='real':\n",
    "                try:                \n",
    "                  df[key] = df[key].asnumeric()  \n",
    "                except:\n",
    "                  targ.remove(key)                  \n",
    "    if y is None:\n",
    "      y=df.columns[-1] \n",
    "    if y in targ:\n",
    "      targ.remove(y)\n",
    "    else:\n",
    "      y=targ.pop()            \n",
    "    return targ    \n",
    "    \n",
    "def predictions(mod,data,run_id):\n",
    "    test = h2o.import_file(data)\n",
    "    mod_perf=mod_best.model_performance(test)\n",
    "              \n",
    "    stats_test={}\n",
    "    stats_test=model_performance_stats(mod_perf)\n",
    "\n",
    "    n=run_id+'_test_stats.json'\n",
    "    dict_to_json(stats_test,n) \n",
    "\n",
    "    try:    \n",
    "      cf=mod_perf.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])\n",
    "      cf_df=cf[0].table.as_data_frame()\n",
    "      cf_df.to_csv(run_id+'_test_confusion_matrix.csv')\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    predictions = mod_best.predict(test)\n",
    "    predictions_df=test.cbind(predictions).as_data_frame() \n",
    "    predictions_df.to_csv(run_id+'_predictions.csv')\n",
    "    return\n",
    "\n",
    "def predictions_test(mod,test,run_id):\n",
    "    mod_perf=mod_best.model_performance(test)          \n",
    "    stats_test={}\n",
    "    stats_test=model_performance_stats(mod_perf)\n",
    "    n=run_id+'_test_stats.json'\n",
    "    dict_to_json(stats_test,n) \n",
    "    try:\n",
    "      cf=mod_perf.confusion_matrix()\n",
    "#      cf=mod_perf.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])\n",
    "      cf_df=cf.table.as_data_frame()\n",
    "      cf_df.to_csv(run_id+'_test_confusion_matrix.csv')\n",
    "    except:\n",
    "      pass\n",
    "    predictions = mod_best.predict(test)    \n",
    "    predictions_df=test.cbind(predictions).as_data_frame() \n",
    "    predictions_df.to_csv(run_id+'_predictions.csv')\n",
    "    return predictions\n",
    "\n",
    "def check_X(x,df):\n",
    "    for name in x:\n",
    "        if name not in df.columns:\n",
    "          x.remove(name)  \n",
    "    return x    \n",
    "    \n",
    "    \n",
    "def get_stacked_ensemble(lst):\n",
    "    se=None\n",
    "    for model in model_set:\n",
    "      if 'BestOfFamily' in model:\n",
    "        se=model\n",
    "    if se is None:     \n",
    "      for model in model_set:\n",
    "        if 'AllModels'in model:\n",
    "          se=model           \n",
    "    return se       \n",
    "    \n",
    "def get_variables_types(df):\n",
    "    d={}\n",
    "    for key, val in df.types.items():\n",
    "        d[key]=val           \n",
    "    return d    \n",
    "    \n",
    "#  End Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r'C:\\Users\\Manvi\\Anaconda3\\indian-liver-patient-records\\indian_liver_patient.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LpQvNq1Qy\n"
     ]
    }
   ],
   "source": [
    "run_id=alphabet(9)\n",
    "if server_path==None:\n",
    "  server_path=os.path.abspath(os.curdir)\n",
    "os.chdir(server_path) \n",
    "run_dir = os.path.join(server_path,run_id)\n",
    "os.mkdir(run_dir)\n",
    "os.chdir(run_dir)    \n",
    "\n",
    "# run_id to std out\n",
    "print (run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manvi\\Anaconda3\\indian-liver-patient-records\\LpQvNq1Qy\\logs   LpQvNq1Qy_autoh2o_log.zip\n"
     ]
    }
   ],
   "source": [
    "logfile=run_id+'_autoh2o_log.zip'\n",
    "logs_path=os.path.join(run_dir,'logs')\n",
    "print(logs_path,' ',logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:43562 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)\n",
      "  Starting server from C:\\Users\\Manvi\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Manvi\\AppData\\Local\\Temp\\tmpyzto3i90\n",
      "  JVM stdout: C:\\Users\\Manvi\\AppData\\Local\\Temp\\tmpyzto3i90\\h2o_Manvi_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Manvi\\AppData\\Local\\Temp\\tmpyzto3i90\\h2o_Manvi_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:43562\n",
      "Connecting to H2O server at http://127.0.0.1:43562 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>10 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_Manvi_gk6jkw</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.752 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:43562</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         04 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.1\n",
       "H2O cluster version age:    10 days\n",
       "H2O cluster name:           H2O_from_python_Manvi_gk6jkw\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.752 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:43562\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.7 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_time': 1555026994.147995, 'target': 'Dataset', 'server_path': 'C:\\\\Users\\\\Manvi\\\\Anaconda3\\\\indian-liver-patient-records', 'data_path': 'C:\\\\Users\\\\Manvi\\\\Anaconda3\\\\indian-liver-patient-records\\\\indian_liver_patient.csv', 'test_path': None, 'max_models': 9, 'run_time': 200, 'run_id': 'LpQvNq1Qy', 'scale': False, 'classification': False, 'model_path': None, 'balance': False, 'balance_threshold': 0.2, 'project': None, 'end_time': 1555026994.147995, 'execution_time': 0.0, 'run_path': 'C:\\\\Users\\\\Manvi\\\\Anaconda3\\\\indian-liver-patient-records\\\\LpQvNq1Qy', 'nthreads': 1, 'min_mem_size': 1, 'analysis': 0}\n"
     ]
    }
   ],
   "source": [
    "meta_data = set_meta_data(analysis, run_id,server_path,data_path,test_path,model_path,target,run_time,classification,scale,max_models,balance_y,balance_threshold,name,run_dir,nthreads,min_mem_size)\n",
    "print(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manvi\\Anaconda3\\indian-liver-patient-records\\indian_liver_patient.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df = h2o.import_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Age</th><th>Gender  </th><th style=\"text-align: right;\">  Total_Bilirubin</th><th style=\"text-align: right;\">  Direct_Bilirubin</th><th style=\"text-align: right;\">  Alkaline_Phosphotase</th><th style=\"text-align: right;\">  Alamine_Aminotransferase</th><th style=\"text-align: right;\">  Aspartate_Aminotransferase</th><th style=\"text-align: right;\">  Total_Protiens</th><th style=\"text-align: right;\">  Albumin</th><th style=\"text-align: right;\">  Albumin_and_Globulin_Ratio</th><th style=\"text-align: right;\">  Dataset</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   65</td><td>Female  </td><td style=\"text-align: right;\">              0.7</td><td style=\"text-align: right;\">               0.1</td><td style=\"text-align: right;\">                   187</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">                          18</td><td style=\"text-align: right;\">             6.8</td><td style=\"text-align: right;\">      3.3</td><td style=\"text-align: right;\">                        0.9 </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   62</td><td>Male    </td><td style=\"text-align: right;\">             10.9</td><td style=\"text-align: right;\">               5.5</td><td style=\"text-align: right;\">                   699</td><td style=\"text-align: right;\">                        64</td><td style=\"text-align: right;\">                         100</td><td style=\"text-align: right;\">             7.5</td><td style=\"text-align: right;\">      3.2</td><td style=\"text-align: right;\">                        0.74</td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   62</td><td>Male    </td><td style=\"text-align: right;\">              7.3</td><td style=\"text-align: right;\">               4.1</td><td style=\"text-align: right;\">                   490</td><td style=\"text-align: right;\">                        60</td><td style=\"text-align: right;\">                          68</td><td style=\"text-align: right;\">             7  </td><td style=\"text-align: right;\">      3.3</td><td style=\"text-align: right;\">                        0.89</td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   58</td><td>Male    </td><td style=\"text-align: right;\">              1  </td><td style=\"text-align: right;\">               0.4</td><td style=\"text-align: right;\">                   182</td><td style=\"text-align: right;\">                        14</td><td style=\"text-align: right;\">                          20</td><td style=\"text-align: right;\">             6.8</td><td style=\"text-align: right;\">      3.4</td><td style=\"text-align: right;\">                        1   </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   72</td><td>Male    </td><td style=\"text-align: right;\">              3.9</td><td style=\"text-align: right;\">               2  </td><td style=\"text-align: right;\">                   195</td><td style=\"text-align: right;\">                        27</td><td style=\"text-align: right;\">                          59</td><td style=\"text-align: right;\">             7.3</td><td style=\"text-align: right;\">      2.4</td><td style=\"text-align: right;\">                        0.4 </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   46</td><td>Male    </td><td style=\"text-align: right;\">              1.8</td><td style=\"text-align: right;\">               0.7</td><td style=\"text-align: right;\">                   208</td><td style=\"text-align: right;\">                        19</td><td style=\"text-align: right;\">                          14</td><td style=\"text-align: right;\">             7.6</td><td style=\"text-align: right;\">      4.4</td><td style=\"text-align: right;\">                        1.3 </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   26</td><td>Female  </td><td style=\"text-align: right;\">              0.9</td><td style=\"text-align: right;\">               0.2</td><td style=\"text-align: right;\">                   154</td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">                          12</td><td style=\"text-align: right;\">             7  </td><td style=\"text-align: right;\">      3.5</td><td style=\"text-align: right;\">                        1   </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   29</td><td>Female  </td><td style=\"text-align: right;\">              0.9</td><td style=\"text-align: right;\">               0.3</td><td style=\"text-align: right;\">                   202</td><td style=\"text-align: right;\">                        14</td><td style=\"text-align: right;\">                          11</td><td style=\"text-align: right;\">             6.7</td><td style=\"text-align: right;\">      3.6</td><td style=\"text-align: right;\">                        1.1 </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   17</td><td>Male    </td><td style=\"text-align: right;\">              0.9</td><td style=\"text-align: right;\">               0.3</td><td style=\"text-align: right;\">                   202</td><td style=\"text-align: right;\">                        22</td><td style=\"text-align: right;\">                          19</td><td style=\"text-align: right;\">             7.4</td><td style=\"text-align: right;\">      4.1</td><td style=\"text-align: right;\">                        1.2 </td><td style=\"text-align: right;\">        2</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   55</td><td>Male    </td><td style=\"text-align: right;\">              0.7</td><td style=\"text-align: right;\">               0.2</td><td style=\"text-align: right;\">                   290</td><td style=\"text-align: right;\">                        53</td><td style=\"text-align: right;\">                          58</td><td style=\"text-align: right;\">             6.8</td><td style=\"text-align: right;\">      3.4</td><td style=\"text-align: right;\">                        1   </td><td style=\"text-align: right;\">        1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target==None:\n",
    "  target=df.columns[27]   \n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "\n",
    "X = []  \n",
    "if all_variables is None:\n",
    "  X=get_independent_variables(df, target)  \n",
    "else: \n",
    "  ivd=get_all_variables_csv(all_variables)    \n",
    "  X=check_all_variables(df, ivd)\n",
    "\n",
    "\n",
    "X=check_X(X,df)\n",
    "\n",
    "\n",
    "# Add independent variables\n",
    "\n",
    "meta_data['X']=X  \n",
    "\n",
    "\n",
    "# impute missing values\n",
    "\n",
    "_=impute_missing_values(df,X, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    df[y] = df[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_y(y,df):\n",
    "  ok=False\n",
    "  C = [name for name in df.columns if name == y]\n",
    "  for key, val in df.types.items():\n",
    "    if key in C:\n",
    "      if val in ['real','int','enum']:        \n",
    "        ok=True         \n",
    "  return ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=check_y(y,df)\n",
    "if not ok:\n",
    "    print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 'int',\n",
       " 'Gender': 'enum',\n",
       " 'Total_Bilirubin': 'real',\n",
       " 'Direct_Bilirubin': 'real',\n",
       " 'Alkaline_Phosphotase': 'int',\n",
       " 'Alamine_Aminotransferase': 'int',\n",
       " 'Aspartate_Aminotransferase': 'int',\n",
       " 'Total_Protiens': 'real',\n",
       " 'Albumin': 'real',\n",
       " 'Albumin_and_Globulin_Ratio': 'real',\n",
       " 'Dataset': 'int'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allV=get_variables_types(df)\n",
    "allV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['variables']=allV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=run_time,project_name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████"
     ]
    }
   ],
   "source": [
    "aml.train(x=X,y=y,training_frame=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['model_execution_time'] = time.time() - model_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_leaderboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_best._id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=get_stacked_ensemble(model_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if se is not None:\n",
    "  mod_best=h2o.get_model(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(mod_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods=mod_best.coef_norm\n",
    "print(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm=stackedensemble_df(aml_leaderboard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_leaderboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get best_models and coef_norm()\n",
    "best_models={}\n",
    "best_models=stackedensemble(mod_best)\n",
    "bm=[]\n",
    "if best_models is not None: \n",
    "  if 'Intercept' in best_models.keys():\n",
    "    del best_models['Intercept']\n",
    "  bm=list(best_models.keys())\n",
    "else:\n",
    "  best_models={}\n",
    "  bm=stackedensemble_df(aml_leaderboard_df)   \n",
    "  for b in bm:   \n",
    "    best_models[b]=None\n",
    "\n",
    "if mod_best.model_id not in bm:\n",
    "    bm.append(mod_best.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_stats=run_id+'_leaderboard.csv'\n",
    "aml_leaderboard_df.to_csv(leaderboard_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top=aml_leaderboard_df.iloc[0]['model_id']\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['mod_best']=mod_best._id\n",
    "meta_data['mod_best_algo']=mod_best.algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['models']=bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path=os.path.join(run_dir,'models')\n",
    "for mod in bm:\n",
    "  try:   \n",
    "    m=h2o.get_model(mod) \n",
    "    h2o.save_model(m, path = models_path)\n",
    "  except:    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM\n",
    " \n",
    "mod,mod_id=get_model_by_algo(\"GBM\",best_models)\n",
    "if mod is not None:\n",
    "    try:     \n",
    "        sh_df=mod.scoring_history()\n",
    "        sh_df.to_csv(run_id+'_gbm_scoring_history.csv') \n",
    "    except:\n",
    "        pass   \n",
    "    try:     \n",
    "        stats_gbm={}\n",
    "        stats_gbm=gbm_stats(mod)\n",
    "        n=run_id+'_gbm_stats.json'\n",
    "        dict_to_json(stats_gbm,n)\n",
    "        print(stats_gbm)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mod is not None:\n",
    "    try:    \n",
    "        sh_df=mod.scoring_history()\n",
    "        sh_df.to_csv(run_id+'_dl_scoring_history.csv') \n",
    "    except:\n",
    "        pass \n",
    "    try:\n",
    "        stats_dl={}\n",
    "        stats_dl=dl_stats(mod)\n",
    "        n=run_id+'_dl_stats.json'\n",
    "        dict_to_json(stats_dl,n)\n",
    "        print(stats_dl)\n",
    "    except:\n",
    "        pass    \n",
    "    try:\n",
    "        cf=mod.confusion_matrix()    \n",
    "        cf_df.to_csv(run_id+'_dl_confusion_matrix.csv')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRF\n",
    "\n",
    "mod,mod_id=get_model_by_algo(\"DRF\",best_models)\n",
    "if mod is not None:\n",
    "    try:     \n",
    "         sh_df=mod.scoring_history()\n",
    "         sh_df.to_csv(run_id+'_drf_scoring_history.csv') \n",
    "    except:\n",
    "         pass  \n",
    "    try: \n",
    "         stats_drf={}\n",
    "         stats_drf=drf_stats(mod)\n",
    "         n=run_id+'_drf_stats.json'\n",
    "         dict_to_json(stats_drf,n)\n",
    "         print(stats_drf)\n",
    "    except:\n",
    "         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XRT\n",
    "\n",
    "mod,mod_id=get_model_by_algo(\"XRT\",best_models)\n",
    "if mod is not None:\n",
    "    try:     \n",
    "         sh_df=mod.scoring_history()\n",
    "         sh_df.to_csv(run_id+'_xrt_scoring_history.csv')\n",
    "    except:\n",
    "         pass     \n",
    "    try:        \n",
    "         stats_xrt={}\n",
    "         stats_xrt=xrt_stats(mod)\n",
    "         n=run_id+'_xrt_stats.json'\n",
    "         dict_to_json(stats_xrt,n)\n",
    "         print(stats_xrt)\n",
    "    except:\n",
    "         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM\n",
    "\n",
    "mod,mod_id=get_model_by_algo(\"GLM\",best_models)\n",
    "if mod is not None:\n",
    "    try:     \n",
    "         stats_glm={}\n",
    "         stats_glm=glm_stats(mod)\n",
    "         n=run_id+'_glm_stats.json'\n",
    "         dict_to_json(stats_glm,n)\n",
    "         print(stats_glm)\n",
    "    except:\n",
    "         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['end_time'] = time.time()\n",
    "meta_data['execution_time'] = meta_data['end_time'] - meta_data['start_time']\n",
    "  \n",
    "n=run_id+'_meta_data.json'\n",
    "dict_to_json(meta_data,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.download_all_logs(dirname=logs_path, filename=logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
